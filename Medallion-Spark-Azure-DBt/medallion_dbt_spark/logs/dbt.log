[0m18:32:57.882162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765B6CDA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765B7024D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765B719890>]}


============================== 18:32:57.891073 | acfd26f3-17f8-4454-b671-074cb8ef6860 ==============================
[0m18:32:57.891073 [info ] [MainThread]: Running with dbt=1.8.6
[0m18:32:57.892821 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:32:58.013381 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:32:58.014406 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:32:58.014935 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:33:00.261821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'acfd26f3-17f8-4454-b671-074cb8ef6860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002767618A010>]}
[0m18:33:00.297848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'acfd26f3-17f8-4454-b671-074cb8ef6860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765AB51F10>]}
[0m18:33:00.297848 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m18:33:00.351615 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m18:33:00.353432 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:33:00.353948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'acfd26f3-17f8-4454-b671-074cb8ef6860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000276761DF3D0>]}
[0m18:33:03.402936 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.medallion_dbt_spark.address_snapshot' (snapshots\address.sql) depends on a source named 'saleslt.address' which was not found
[0m18:33:03.402936 [debug] [MainThread]: Command `dbt snapshot` failed at 18:33:03.402936 after 5.60 seconds
[0m18:33:03.402936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765B719650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027654DD13D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002765B2B7E50>]}
[0m18:33:03.402936 [debug] [MainThread]: Flushing usage events
[0m18:35:35.126425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C855C72990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C855C72690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C855C5F190>]}


============================== 18:35:35.130314 | 079b0f15-d9a1-4d1c-8514-a2d3ff20eb72 ==============================
[0m18:35:35.130314 [info ] [MainThread]: Running with dbt=1.8.6
[0m18:35:35.130314 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:35:35.173409 [info ] [MainThread]: dbt version: 1.8.6
[0m18:35:35.173409 [info ] [MainThread]: python version: 3.11.3
[0m18:35:35.180510 [info ] [MainThread]: python path: c:\Users\huynh\Desktop\Data_Engineer\.venv\Scripts\python.exe
[0m18:35:35.181538 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m18:35:35.298277 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:35:35.299341 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:35:35.300505 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:35:36.940808 [info ] [MainThread]: Using profiles dir at C:\Users\huynh\.dbt
[0m18:35:36.941809 [info ] [MainThread]: Using profiles.yml file at C:\Users\huynh\.dbt\profiles.yml
[0m18:35:36.943384 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\huynh\Desktop\Medallion-Spark-Azure-DBt\medallion_dbt_spark\dbt_project.yml
[0m18:35:36.944404 [info ] [MainThread]: adapter type: databricks
[0m18:35:36.945411 [info ] [MainThread]: adapter version: 1.8.6
[0m18:35:37.014961 [info ] [MainThread]: Configuration:
[0m18:35:37.014961 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:35:37.014961 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:35:37.014961 [info ] [MainThread]: Required dependencies:
[0m18:35:37.023164 [debug] [MainThread]: Executing "git --help"
[0m18:35:37.057797 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:35:37.059757 [debug] [MainThread]: STDERR: "b''"
[0m18:35:37.061925 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:35:37.062322 [info ] [MainThread]: Connection:
[0m18:35:37.063354 [info ] [MainThread]:   host: adb-3626580605752482.2.azuredatabricks.net
[0m18:35:37.064378 [info ] [MainThread]:   http_path: sql/protocolv1/o/3626580605752482/0920-092432-bp1lg2h2
[0m18:35:37.065371 [info ] [MainThread]:   catalog: hive_metastore
[0m18:35:37.066375 [info ] [MainThread]:   schema: saleslt
[0m18:35:37.067379 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m18:35:37.071194 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(23112, 22860), compute-name=) - Creating connection
[0m18:35:37.071194 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m18:35:37.072199 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23112, 22860), compute-name=) - Acquired connection on thread (23112, 22860), using default compute resource
[0m18:35:37.072199 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23112, 22860), compute-name=) - Checking idleness
[0m18:35:37.073190 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=None, name=debug, idle-time=0.0009920597076416016s, acquire-count=1, language=None, thread-identifier=(23112, 22860), compute-name=) - Retrieving connection
[0m18:35:37.074302 [debug] [MainThread]: Using databricks connection "debug"
[0m18:35:37.074302 [debug] [MainThread]: On debug: select 1 as id
[0m18:35:37.074302 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:35:37.509732 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=02395dac-b689-439a-9817-0cd89e37eb86, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23112, 22860), compute-name=) - Connection created
[0m18:35:37.509732 [debug] [MainThread]: Databricks adapter: Cursor(session-id=02395dac-b689-439a-9817-0cd89e37eb86, command-id=Unknown) - Created cursor
[0m18:35:37.958666 [debug] [MainThread]: SQL status: OK in 0.880 seconds
[0m18:35:37.959871 [debug] [MainThread]: Databricks adapter: Cursor(session-id=02395dac-b689-439a-9817-0cd89e37eb86, command-id=17b73dd2-887d-4407-b825-4136a05f8a7b) - Closing cursor
[0m18:35:37.962605 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960389219536, session-id=02395dac-b689-439a-9817-0cd89e37eb86, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23112, 22860), compute-name=) - Released connection
[0m18:35:37.962605 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:35:37.964685 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:35:37.966743 [debug] [MainThread]: Command `dbt debug` succeeded at 18:35:37.966743 after 2.92 seconds
[0m18:35:37.966743 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:35:37.966743 [debug] [MainThread]: On debug: Close
[0m18:35:37.966743 [debug] [MainThread]: Databricks adapter: Connection(session-id=02395dac-b689-439a-9817-0cd89e37eb86) - Closing connection
[0m18:35:38.059306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C84F2D13D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C87053BF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8706DA490>]}
[0m18:35:38.060319 [debug] [MainThread]: Flushing usage events
[0m18:35:57.072516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C09CC290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C0A19650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C0A02E10>]}


============================== 18:35:57.075593 | f37c67c1-1867-4591-b992-1a50fb1caaff ==============================
[0m18:35:57.075593 [info ] [MainThread]: Running with dbt=1.8.6
[0m18:35:57.078379 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:35:57.182462 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:35:57.182462 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:35:57.182462 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:35:58.861987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f37c67c1-1867-4591-b992-1a50fb1caaff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6DB49B510>]}
[0m18:35:58.908400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f37c67c1-1867-4591-b992-1a50fb1caaff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6DB301F10>]}
[0m18:35:58.908400 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m18:35:58.930174 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m18:35:58.930174 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:35:58.930174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f37c67c1-1867-4591-b992-1a50fb1caaff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C09E8A10>]}
[0m18:36:00.557062 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.medallion_dbt_spark.address_snapshot' (snapshots\address.sql) depends on a source named 'saleslt.address' which was not found
[0m18:36:00.581112 [debug] [MainThread]: Command `dbt snapshot` failed at 18:36:00.581112 after 3.57 seconds
[0m18:36:00.581798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C0A1B910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6BA0513D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6C052DA50>]}
[0m18:36:00.582676 [debug] [MainThread]: Flushing usage events
[0m18:39:26.046810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002303E0EC990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002303E133390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002303CE90510>]}


============================== 18:39:26.047342 | f8a6a229-6655-469a-b098-2b177904fad1 ==============================
[0m18:39:26.047342 [info ] [MainThread]: Running with dbt=1.8.6
[0m18:39:26.047342 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:39:26.168794 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:39:26.168794 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:39:26.169829 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:39:27.834607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058B42050>]}
[0m18:39:27.865779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000230586636D0>]}
[0m18:39:27.865779 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m18:39:27.881391 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m18:39:27.881391 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:39:27.881391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058BB8550>]}
[0m18:39:29.755978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058F74410>]}
[0m18:39:29.929631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058E9FC10>]}
[0m18:39:29.931013 [info ] [MainThread]: Found 2 models, 7 snapshots, 4 data tests, 9 sources, 596 macros
[0m18:39:29.931534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058DED310>]}
[0m18:39:29.934840 [info ] [MainThread]: 
[0m18:39:29.934840 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7444, 10748), compute-name=) - Creating connection
[0m18:39:29.934840 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:39:29.934840 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Acquired connection on thread (7444, 10748), using default compute resource
[0m18:39:29.945569 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=None, name=list_hive_metastore, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7444, 19104), compute-name=) - Creating connection
[0m18:39:29.946698 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore'
[0m18:39:29.946698 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=None, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Acquired connection on thread (7444, 19104), using default compute resource
[0m18:39:29.946698 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=None, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Checking idleness
[0m18:39:29.946698 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=None, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Retrieving connection
[0m18:39:29.949253 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore"
[0m18:39:29.949253 [debug] [ThreadPool]: On list_hive_metastore: GetSchemas(database=hive_metastore, schema=None)
[0m18:39:29.950311 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:30.353208 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Connection created
[0m18:39:30.354198 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, command-id=Unknown) - Created cursor
[0m18:39:30.629512 [debug] [ThreadPool]: SQL status: OK in 0.680 seconds
[0m18:39:30.656969 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, command-id=66e0cbe5-4164-44f3-81f4-70c4cf75817e) - Closing cursor
[0m18:39:30.656969 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=list_hive_metastore, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 19104), compute-name=) - Released connection
[0m18:39:30.656969 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=list_hive_metastore, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 19104), compute-name=) - Checking idleness
[0m18:39:30.659913 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore, now create_hive_metastore_snapshots)
[0m18:39:30.659913 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.0029439926147460938s, acquire-count=0, language=None, thread-identifier=(7444, 19104), compute-name=) - Reusing connection previously named list_hive_metastore
[0m18:39:30.661474 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.004503965377807617s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Acquired connection on thread (7444, 19104), using default compute resource
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Checking idleness
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=2, language=None, thread-identifier=(7444, 19104), compute-name=) - Acquired connection on thread (7444, 19104), using default compute resource
[0m18:39:30.662620 [debug] [ThreadPool]: Creating schema "database: "hive_metastore"
schema: "snapshots"
"
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=2, language=None, thread-identifier=(7444, 19104), compute-name=) - Checking idleness
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=2, language=None, thread-identifier=(7444, 19104), compute-name=) - Retrieving connection
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=2, language=None, thread-identifier=(7444, 19104), compute-name=) - Checking idleness
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.00565028190612793s, acquire-count=2, language=None, thread-identifier=(7444, 19104), compute-name=) - Retrieving connection
[0m18:39:30.662620 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:39:30.662620 [debug] [ThreadPool]: Using databricks connection "create_hive_metastore_snapshots"
[0m18:39:30.662620 [debug] [ThreadPool]: On create_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "create_hive_metastore_snapshots"} */
create schema if not exists `hive_metastore`.`snapshots`
  
[0m18:39:30.662620 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, command-id=Unknown) - Created cursor
[0m18:39:31.001923 [debug] [ThreadPool]: SQL status: OK in 0.340 seconds
[0m18:39:31.001923 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, command-id=bef138e8-0d60-48aa-9e8a-86aa813ff781) - Closing cursor
[0m18:39:31.001923 [debug] [ThreadPool]: Spark adapter: NotImplemented: commit
[0m18:39:31.001923 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.3449537754058838s, acquire-count=1, language=None, thread-identifier=(7444, 19104), compute-name=) - Released connection
[0m18:39:31.001923 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406674146640, session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1, name=create_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 19104), compute-name=) - Released connection
[0m18:39:31.013692 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7444, 8860), compute-name=) - Creating connection
[0m18:39:31.014925 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m18:39:31.015500 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Acquired connection on thread (7444, 8860), using default compute resource
[0m18:39:31.015500 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:31.017131 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Retrieving connection
[0m18:39:31.017131 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m18:39:31.017131 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m18:39:31.017131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:31.583625 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Connection created
[0m18:39:31.583625 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=Unknown) - Created cursor
[0m18:39:31.874650 [debug] [ThreadPool]: SQL status: OK in 0.860 seconds
[0m18:39:31.889646 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=ffbb4d57-5569-40d4-a35b-6100ebf0b6ab) - Closing cursor
[0m18:39:31.892368 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.3087425231933594s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:31.892368 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.3087425231933594s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Retrieving connection
[0m18:39:31.892368 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.3087425231933594s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:31.892368 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.3087425231933594s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Retrieving connection
[0m18:39:31.892368 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:39:31.892368 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m18:39:31.892368 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m18:39:31.892368 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=Unknown) - Created cursor
[0m18:39:32.197689 [debug] [ThreadPool]: SQL status: OK in 0.310 seconds
[0m18:39:32.200700 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=f21b582d-ee6a-45db-ba9b-38666f6401c7) - Closing cursor
[0m18:39:32.203404 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.6197786331176758s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:32.203404 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.6197786331176758s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Retrieving connection
[0m18:39:32.203404 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m18:39:32.203404 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m18:39:32.203404 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=Unknown) - Created cursor
[0m18:39:32.451154 [debug] [ThreadPool]: SQL status: OK in 0.250 seconds
[0m18:39:32.451154 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=32f451bb-471b-44f4-900f-aec18a736f4c) - Closing cursor
[0m18:39:32.451154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 8860), compute-name=) - Released connection
[0m18:39:32.451154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:32.451154 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m18:39:32.451154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 8860), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m18:39:32.451154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Acquired connection on thread (7444, 8860), using default compute resource
[0m18:39:32.467283 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_snapshots, idle-time=0.0161287784576416s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Checking idleness
[0m18:39:32.467283 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_snapshots, idle-time=0.0161287784576416s, acquire-count=1, language=None, thread-identifier=(7444, 8860), compute-name=) - Retrieving connection
[0m18:39:32.469251 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m18:39:32.469251 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m18:39:32.471898 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=Unknown) - Created cursor
[0m18:39:32.702665 [debug] [ThreadPool]: SQL status: OK in 0.230 seconds
[0m18:39:32.705665 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, command-id=afcef6f6-7b87-48d8-97aa-64cbc8226bd8) - Closing cursor
[0m18:39:32.706197 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2406667778512, session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 8860), compute-name=) - Released connection
[0m18:39:32.707239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058DE1350>]}
[0m18:39:32.708434 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=2.773592948913574s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Checking idleness
[0m18:39:32.708964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=2.774123191833496s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Retrieving connection
[0m18:39:32.708964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=2.774123191833496s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Checking idleness
[0m18:39:32.708964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=2.774123191833496s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Retrieving connection
[0m18:39:32.710315 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:39:32.710858 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:39:32.710858 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 10748), compute-name=) - Released connection
[0m18:39:32.710858 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:39:32.712345 [info ] [MainThread]: 
[0m18:39:32.721562 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.address_snapshot
[0m18:39:32.721562 [info ] [Thread-1 (]: 1 of 7 START snapshot snapshots.address_snapshot ............................... [RUN]
[0m18:39:32.724294 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7444, 13984), compute-name=) - Creating connection
[0m18:39:32.724294 [debug] [Thread-1 (]: Acquiring new databricks connection 'snapshot.medallion_dbt_spark.address_snapshot'
[0m18:39:32.725338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`address_snapshot`'
[0m18:39:32.725338 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.address_snapshot
[0m18:39:32.737463 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.address_snapshot
[0m18:39:32.814004 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.address_snapshot"
[0m18:39:32.830659 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.10532093048095703s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:32.832161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.10532093048095703s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:39:32.832161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.10682320594787598s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:32.832161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.10682320594787598s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:39:32.832161 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:39:32.832161 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.address_snapshot"
[0m18:39:32.832161 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.address_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.address_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`address_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/address/address_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(AddressID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        AddressID,
        AddressLine1,
        AddressLine2,
        City,
        StateProvince,
        CountryRegion,
        PostalCode
    from `hive_metastore`.`saleslt`.`address`
)
select *
from source_data

    ) sbq



  
      
[0m18:39:32.832161 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:39:33.135109 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Connection created
[0m18:39:33.136250 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:39:48.124805 [debug] [Thread-1 (]: SQL status: OK in 15.290 seconds
[0m18:39:48.124805 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=ec0b541b-fc5a-4c01-9d1c-a4305ee0987b) - Closing cursor
[0m18:39:48.328625 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:39:48.328625 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:48.328625 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:48.328625 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058936CD0>]}
[0m18:39:48.328625 [info ] [Thread-1 (]: 1 of 7 OK snapshotted snapshots.address_snapshot ............................... [[32mOK[0m in 15.61s]
[0m18:39:48.328625 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.address_snapshot
[0m18:39:48.341366 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customer_snapshot
[0m18:39:48.341366 [info ] [Thread-1 (]: 2 of 7 START snapshot snapshots.customer_snapshot .............................. [RUN]
[0m18:39:48.344378 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.01575303077697754s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:48.345559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.address_snapshot, now snapshot.medallion_dbt_spark.customer_snapshot)
[0m18:39:48.345559 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.016933917999267578s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.address_snapshot
[0m18:39:48.345559 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.016933917999267578s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`customer_snapshot`'
[0m18:39:48.345559 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customer_snapshot
[0m18:39:48.345559 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customer_snapshot
[0m18:39:48.345559 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.customer_snapshot"
[0m18:39:48.345559 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.016933917999267578s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:48.345559 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.016933917999267578s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:39:48.345559 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.customer_snapshot"
[0m18:39:48.345559 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.customer_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.customer_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`customer_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/customer/customer_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(CustomerId as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        CustomerId,
        NameStyle,
        Title,
        FirstName,
        MiddleName,
        LastName,
        Suffix,
        CompanyName,
        SalesPerson,
        EmailAddress,
        Phone,
        PasswordHash,
        PasswordSalt
    from `hive_metastore`.`saleslt`.`customer`
)
select *
from source_data

    ) sbq



  
      
[0m18:39:48.345559 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:39:53.216297 [debug] [Thread-1 (]: SQL status: OK in 4.870 seconds
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=a248df74-2219-4f4a-95b4-98319d72f36a) - Closing cursor
[0m18:39:53.217804 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:53.217804 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058A10510>]}
[0m18:39:53.217804 [info ] [Thread-1 (]: 2 of 7 OK snapshotted snapshots.customer_snapshot .............................. [[32mOK[0m in 4.87s]
[0m18:39:53.217804 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customer_snapshot
[0m18:39:53.217804 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m18:39:53.217804 [info ] [Thread-1 (]: 3 of 7 START snapshot snapshots.customeraddress_snapshot ....................... [RUN]
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:53.217804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customer_snapshot, now snapshot.medallion_dbt_spark.customeraddress_snapshot)
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customer_snapshot
[0m18:39:53.217804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`customeraddress_snapshot`'
[0m18:39:53.217804 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m18:39:53.236097 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m18:39:53.240823 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.customeraddress_snapshot"
[0m18:39:53.242623 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.024819135665893555s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:53.243751 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.025946855545043945s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:39:53.244255 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.customeraddress_snapshot"
[0m18:39:53.244255 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.customeraddress_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.customeraddress_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`customeraddress_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/customeraddress/customeraddress_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(CustomerId||'-'||AddressId as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        CustomerId,
        AddressId,
        AddressType
    from `hive_metastore`.`saleslt`.`customeraddress`
)
select *
from source_data

    ) sbq



  
      
[0m18:39:53.244255 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:39:57.959345 [debug] [Thread-1 (]: SQL status: OK in 4.720 seconds
[0m18:39:57.959345 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=dbcd59e0-91bd-4fc5-ae25-2d888985e41d) - Closing cursor
[0m18:39:57.959345 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:39:57.959345 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:57.959345 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:39:57.959345 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058A15E10>]}
[0m18:39:57.959345 [info ] [Thread-1 (]: 3 of 7 OK snapshotted snapshots.customeraddress_snapshot ....................... [[32mOK[0m in 4.74s]
[0m18:39:57.965878 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m18:39:57.967183 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.product_snapshot
[0m18:39:57.967183 [info ] [Thread-1 (]: 4 of 7 START snapshot snapshots.product_snapshot ............................... [RUN]
[0m18:39:57.969122 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.009776830673217773s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:57.969122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customeraddress_snapshot, now snapshot.medallion_dbt_spark.product_snapshot)
[0m18:39:57.970958 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.009776830673217773s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m18:39:57.970958 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.011613130569458008s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`product_snapshot`'
[0m18:39:57.970958 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.product_snapshot
[0m18:39:57.974118 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.product_snapshot
[0m18:39:57.974118 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.product_snapshot"
[0m18:39:57.981647 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.022301435470581055s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:39:57.983147 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.02380204200744629s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:39:57.983776 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.product_snapshot"
[0m18:39:57.984207 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.product_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.product_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`product_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/product/product_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(ProductID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with product_snapshot as (
    SELECT
        ProductID,
        Name,
        ProductNumber,
        Color,
        StandardCost,
        ListPrice,
        Size,
        Weight,
        ProductCategoryID,
        ProductModelID,
        SellStartDate,
        SellEndDate,
        DiscontinuedDate,
        ThumbNailPhoto,
        ThumbnailPhotoFileName
    FROM `hive_metastore`.`saleslt`.`product`
)

select * from product_snapshot

    ) sbq



  
      
[0m18:39:57.984862 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:40:02.263360 [debug] [Thread-1 (]: SQL status: OK in 4.280 seconds
[0m18:40:02.263360 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=28a46582-50ab-471e-9e47-2480deca1d8d) - Closing cursor
[0m18:40:02.263360 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:40:02.263360 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:02.263360 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:02.268780 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002303E57D710>]}
[0m18:40:02.269298 [info ] [Thread-1 (]: 4 of 7 OK snapshotted snapshots.product_snapshot ............................... [[32mOK[0m in 4.30s]
[0m18:40:02.269298 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.product_snapshot
[0m18:40:02.271159 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m18:40:02.272024 [info ] [Thread-1 (]: 5 of 7 START snapshot snapshots.productmodel_snapshot .......................... [RUN]
[0m18:40:02.273068 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.008664131164550781s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:02.273068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.product_snapshot, now snapshot.medallion_dbt_spark.productmodel_snapshot)
[0m18:40:02.274103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.009708642959594727s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.product_snapshot
[0m18:40:02.274103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.01074361801147461s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`productmodel_snapshot`'
[0m18:40:02.275102 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m18:40:02.278115 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m18:40:02.285326 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.productmodel_snapshot"
[0m18:40:02.287909 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.023584842681884766s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:02.288327 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.024966716766357422s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:40:02.289355 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.productmodel_snapshot"
[0m18:40:02.290374 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.productmodel_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.productmodel_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`productmodel_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/productmodel/productmodel_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(ProductModelID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with product_snapshot as (
    SELECT
        ProductModelID,
        Name,
        CatalogDescription
    FROM `hive_metastore`.`saleslt`.`productmodel`
)

select * from product_snapshot

    ) sbq



  
      
[0m18:40:02.290374 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:40:06.193667 [debug] [Thread-1 (]: SQL status: OK in 3.900 seconds
[0m18:40:06.194771 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=56fbd4f5-c775-4c2d-8f8f-4c5c2157e209) - Closing cursor
[0m18:40:06.196777 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:40:06.197777 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:06.198777 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:06.198777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058BED5D0>]}
[0m18:40:06.199777 [info ] [Thread-1 (]: 5 of 7 OK snapshotted snapshots.productmodel_snapshot .......................... [[32mOK[0m in 3.93s]
[0m18:40:06.201777 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m18:40:06.202557 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m18:40:06.202557 [info ] [Thread-1 (]: 6 of 7 START snapshot snapshots.salesorderdetail_snapshot ...................... [RUN]
[0m18:40:06.202557 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0037794113159179688s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:06.202557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.productmodel_snapshot, now snapshot.medallion_dbt_spark.salesorderdetail_snapshot)
[0m18:40:06.205470 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0066928863525390625s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.productmodel_snapshot
[0m18:40:06.205470 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0066928863525390625s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderdetail_snapshot`'
[0m18:40:06.205470 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m18:40:06.205470 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m18:40:06.205470 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"
[0m18:40:06.216260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.01748347282409668s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:06.216260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.01748347282409668s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:40:06.216260 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"
[0m18:40:06.217793 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.salesorderdetail_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`salesorderdetail_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/salesorderdetail/salesorderdetail_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(SalesOrderDetailID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with salesorderdetail_snapshot as (
    SELECT
        SalesOrderID,
        SalesOrderDetailID,
        OrderQty,
        ProductID,
        UnitPrice,
        UnitPriceDiscount,
        LineTotal
    FROM `hive_metastore`.`saleslt`.`salesorderdetail`
)

select * from salesorderdetail_snapshot

    ) sbq



  
      
[0m18:40:06.219004 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:40:11.048593 [debug] [Thread-1 (]: SQL status: OK in 4.830 seconds
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=e5c1cf93-0ec6-4cc2-9cff-a6d3d721acb3) - Closing cursor
[0m18:40:11.064231 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:11.064231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002305899D650>]}
[0m18:40:11.064231 [info ] [Thread-1 (]: 6 of 7 OK snapshotted snapshots.salesorderdetail_snapshot ...................... [[32mOK[0m in 4.86s]
[0m18:40:11.064231 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m18:40:11.064231 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m18:40:11.064231 [info ] [Thread-1 (]: 7 of 7 START snapshot snapshots.salesorderheader_snapshot ...................... [RUN]
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:11.064231 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderdetail_snapshot, now snapshot.medallion_dbt_spark.salesorderheader_snapshot)
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m18:40:11.064231 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Acquired connection on thread (7444, 13984), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderheader_snapshot`'
[0m18:40:11.064231 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m18:40:11.079847 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m18:40:11.079847 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.salesorderheader_snapshot"
[0m18:40:11.079847 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.015616416931152344s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Checking idleness
[0m18:40:11.079847 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.015616416931152344s, acquire-count=1, language=sql, thread-identifier=(7444, 13984), compute-name=) - Retrieving connection
[0m18:40:11.079847 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.salesorderheader_snapshot"
[0m18:40:11.079847 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.salesorderheader_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`salesorderheader_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/salesorderheader/salesorderheader_snapshot'
      
      
      as
      
    

    select *,
        md5(coalesce(cast(SalesOrderID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with salesorderheader_snapshot as (
    SELECT
        SalesOrderID,
        RevisionNumber,
        OrderDate,
        DueDate,
        ShipDate,
        Status,
        OnlineOrderFlag,
        SalesOrderNumber,
        PurchaseOrderNumber,
        AccountNumber,
        CustomerID,
        ShipToAddressID,
        BillToAddressID,
        ShipMethod,
        CreditCardApprovalCode,
        SubTotal,
        TaxAmt,
        Freight,
        TotalDue,
        Comment
    FROM `hive_metastore`.`saleslt`.`salesorderheader`
)

select * from salesorderheader_snapshot

    ) sbq



  
      
[0m18:40:11.079847 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=Unknown) - Created cursor
[0m18:40:14.904706 [debug] [Thread-1 (]: SQL status: OK in 3.820 seconds
[0m18:40:14.904706 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, command-id=f2f56e5f-615d-4caf-8b1d-5777735cf1a4) - Closing cursor
[0m18:40:14.904706 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m18:40:14.904706 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:14.904706 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2406671180496, session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7444, 13984), compute-name=) - Released connection
[0m18:40:14.904706 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8a6a229-6655-469a-b098-2b177904fad1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023058BD5410>]}
[0m18:40:14.904706 [info ] [Thread-1 (]: 7 of 7 OK snapshotted snapshots.salesorderheader_snapshot ...................... [[32mOK[0m in 3.84s]
[0m18:40:14.904706 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m18:40:14.904706 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=42.19384789466858s, acquire-count=0, language=None, thread-identifier=(7444, 10748), compute-name=) - Checking idleness
[0m18:40:14.915713 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=42.20485472679138s, acquire-count=0, language=None, thread-identifier=(7444, 10748), compute-name=) - Reusing connection previously named master
[0m18:40:14.916257 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=42.20539879798889s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Acquired connection on thread (7444, 10748), using default compute resource
[0m18:40:14.916257 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=42.20539879798889s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Checking idleness
[0m18:40:14.917862 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=None, name=master, idle-time=42.20700407028198s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Retrieving connection
[0m18:40:14.918381 [debug] [MainThread]: On master: ROLLBACK
[0m18:40:14.918381 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:40:15.226346 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=48461284-f469-40a2-a197-c220ee7f0cc0, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Connection created
[0m18:40:15.226346 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m18:40:15.226346 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=48461284-f469-40a2-a197-c220ee7f0cc0, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Checking idleness
[0m18:40:15.226346 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=48461284-f469-40a2-a197-c220ee7f0cc0, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(7444, 10748), compute-name=) - Retrieving connection
[0m18:40:15.226346 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:40:15.226346 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:40:15.226346 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2406672635344, session-id=48461284-f469-40a2-a197-c220ee7f0cc0, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7444, 10748), compute-name=) - Released connection
[0m18:40:15.241948 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:40:15.245805 [debug] [MainThread]: On master: ROLLBACK
[0m18:40:15.247434 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m18:40:15.248790 [debug] [MainThread]: On master: Close
[0m18:40:15.249822 [debug] [MainThread]: Databricks adapter: Connection(session-id=48461284-f469-40a2-a197-c220ee7f0cc0) - Closing connection
[0m18:40:15.337665 [debug] [MainThread]: Connection 'create_hive_metastore_snapshots' was properly closed.
[0m18:40:15.338661 [debug] [MainThread]: On create_hive_metastore_snapshots: ROLLBACK
[0m18:40:15.339660 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m18:40:15.339660 [debug] [MainThread]: On create_hive_metastore_snapshots: Close
[0m18:40:15.340659 [debug] [MainThread]: Databricks adapter: Connection(session-id=ce0081d4-ac91-41fb-a38e-f2f31418b2f1) - Closing connection
[0m18:40:15.443367 [debug] [MainThread]: Connection 'list_hive_metastore_snapshots' was properly closed.
[0m18:40:15.445725 [debug] [MainThread]: On list_hive_metastore_snapshots: ROLLBACK
[0m18:40:15.446750 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m18:40:15.448730 [debug] [MainThread]: On list_hive_metastore_snapshots: Close
[0m18:40:15.451738 [debug] [MainThread]: Databricks adapter: Connection(session-id=717aa5e7-7c7f-4b55-946b-41f300750f0d) - Closing connection
[0m18:40:15.624545 [debug] [MainThread]: Connection 'snapshot.medallion_dbt_spark.salesorderheader_snapshot' was properly closed.
[0m18:40:15.625616 [debug] [MainThread]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: ROLLBACK
[0m18:40:15.625616 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m18:40:15.625616 [debug] [MainThread]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: Close
[0m18:40:15.625616 [debug] [MainThread]: Databricks adapter: Connection(session-id=5fe4c1bd-31f9-4cfa-b0a9-6b2f50c2e416) - Closing connection
[0m18:40:15.714882 [info ] [MainThread]: 
[0m18:40:15.714882 [info ] [MainThread]: Finished running 7 snapshots in 0 hours 0 minutes and 45.78 seconds (45.78s).
[0m18:40:15.714882 [debug] [MainThread]: Command end result
[0m18:40:15.812884 [info ] [MainThread]: 
[0m18:40:15.814334 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:40:15.814334 [info ] [MainThread]: 
[0m18:40:15.815780 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m18:40:15.816939 [debug] [MainThread]: Command `dbt snapshot` succeeded at 18:40:15.816939 after 49.83 seconds
[0m18:40:15.817950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000230377913D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023037A63F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000230377D2090>]}
[0m18:40:15.817950 [debug] [MainThread]: Flushing usage events
[0m19:14:35.659224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB3E266F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB3E252990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB3E251B90>]}


============================== 19:14:35.666229 | 50de166e-394c-4cf5-9afb-1f0e18ebad42 ==============================
[0m19:14:35.666229 [info ] [MainThread]: Running with dbt=1.8.6
[0m19:14:35.668235 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:14:35.784406 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:14:35.785406 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:14:35.786406 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:14:37.891394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB58AE3FD0>]}
[0m19:14:37.939096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB587A3690>]}
[0m19:14:37.939096 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m19:14:37.951851 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 6 files added, 0 files changed.
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\product\dim_product.sql
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\customer\dim_customer.yml
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\customer\dim_customer.sql
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\sales\sales.sql
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\product\dim_product.yml
[0m19:14:38.223484 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models\marts\sales\sales.yml
[0m19:14:38.424172 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m19:14:38.424172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB58F4D2D0>]}
[0m19:14:38.439329 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_customers' in the 'models' section of file 'models\marts\customer\dim_customer.yml'
[0m19:14:38.526487 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_products' in the 'models' section of file 'models\marts\product\dim_product.yml'
[0m19:14:38.544872 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_sales' in the 'models' section of file 'models\marts\sales\sales.yml'
[0m19:14:38.579215 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_customers_customer_sk.22a014df62' (models\marts\customer\dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m19:14:38.579215 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_customer_sk.8ae5836863' (models\marts\customer\dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m19:14:38.579215 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_customerid.209fbdda85' (models\marts\customer\dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m19:14:38.586034 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_AddressId.86b771f63e' (models\marts\customer\dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m19:14:38.587812 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_products_product_sk.8f20ac7c5b' (models\marts\product\dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m19:14:38.590044 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_product_sk.2a2df3e1b9' (models\marts\product\dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m19:14:38.591667 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_product_name.991aec73f3' (models\marts\product\dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m19:14:38.592176 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_sellstartdate.f97a265a0f' (models\marts\product\dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m19:14:38.594393 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.596476 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.596476 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.598616 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.599938 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.600998 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.602379 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.602887 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.604090 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.605181 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.607205 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.609531 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.611478 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.613132 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.614306 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.614306 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.615923 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.617078 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.617078 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023' (models\marts\sales\sales.yml) depends on a node named 'dim_sales' in package '' which was not found
[0m19:14:38.707358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB590C3B10>]}
[0m19:14:38.870436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB593CFFD0>]}
[0m19:14:38.870946 [info ] [MainThread]: Found 5 models, 7 snapshots, 4 data tests, 9 sources, 596 macros
[0m19:14:38.870946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB590FA8D0>]}
[0m19:14:38.875250 [info ] [MainThread]: 
[0m19:14:38.875250 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(15268, 9480), compute-name=) - Creating connection
[0m19:14:38.875250 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:14:38.875250 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Acquired connection on thread (15268, 9480), using default compute resource
[0m19:14:38.884966 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=None, name=list_hive_metastore_snapshots, idle-time=0s, acquire-count=0, language=None, thread-identifier=(15268, 13336), compute-name=) - Creating connection
[0m19:14:38.885369 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_snapshots'
[0m19:14:38.886374 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Acquired connection on thread (15268, 13336), using default compute resource
[0m19:14:38.886848 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0004744529724121094s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:38.887873 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0014989376068115234s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:38.887873 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:14:38.889324 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m19:14:38.889324 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:39.399388 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Connection created
[0m19:14:39.399388 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:39.722309 [debug] [ThreadPool]: SQL status: OK in 0.830 seconds
[0m19:14:39.742324 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=99d50654-8259-4e1a-a3bb-683cda8b4da7) - Closing cursor
[0m19:14:39.754100 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.35471224784851074s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:39.754100 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.35471224784851074s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:39.755388 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.3560001850128174s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:39.755388 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.3560001850128174s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:39.755388 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:14:39.756646 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:14:39.757175 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m19:14:39.757175 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:40.019244 [debug] [ThreadPool]: SQL status: OK in 0.260 seconds
[0m19:14:40.021801 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=609cc4c9-9bc9-4397-b442-b86a3f8ce1c9) - Closing cursor
[0m19:14:40.116036 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.7166481018066406s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:40.116036 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.7166481018066406s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:40.116036 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:14:40.116036 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m19:14:40.116036 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:40.321267 [debug] [ThreadPool]: SQL status: OK in 0.210 seconds
[0m19:14:40.324632 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=34c9364f-07f0-444a-b932-77959d96f49b) - Closing cursor
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 13336), compute-name=) - Released connection
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:40.325148 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now list_hive_metastore_saleslt)
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 13336), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Acquired connection on thread (15268, 13336), using default compute resource
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:40.325148 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:14:40.325148 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m19:14:40.325148 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:40.447766 [debug] [ThreadPool]: SQL status: OK in 0.120 seconds
[0m19:14:40.447766 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=303a586e-a4e1-4d42-9183-fbe86a33dfc7) - Closing cursor
[0m19:14:40.447766 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.12261843681335449s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:40.447766 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.12261843681335449s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:40.447766 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:14:40.447766 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m19:14:40.447766 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:40.746066 [debug] [ThreadPool]: SQL status: OK in 0.300 seconds
[0m19:14:40.746066 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=d41edca5-9563-4efc-a64d-295e68efcdbd) - Closing cursor
[0m19:14:40.746066 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.42091798782348633s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Checking idleness
[0m19:14:40.746066 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.42091798782348633s, acquire-count=1, language=None, thread-identifier=(15268, 13336), compute-name=) - Retrieving connection
[0m19:14:40.746066 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:14:40.746066 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m19:14:40.746066 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=Unknown) - Created cursor
[0m19:14:40.995239 [debug] [ThreadPool]: SQL status: OK in 0.250 seconds
[0m19:14:40.995239 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, command-id=7050613f-6bfe-44d1-a02d-9ef5832e57f0) - Closing cursor
[0m19:14:40.995239 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2934957366416, session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 13336), compute-name=) - Released connection
[0m19:14:40.995239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50de166e-394c-4cf5-9afb-1f0e18ebad42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB5912CB90>]}
[0m19:14:40.995239 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=2.119988441467285s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Checking idleness
[0m19:14:40.995239 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=2.119988441467285s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Retrieving connection
[0m19:14:40.995239 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=2.119988441467285s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Checking idleness
[0m19:14:40.995239 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=2.119988441467285s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Retrieving connection
[0m19:14:41.006669 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:14:41.006669 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:14:41.006669 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 9480), compute-name=) - Released connection
[0m19:14:41.006669 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:41.006669 [info ] [MainThread]: 
[0m19:14:41.012141 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:14:41.012141 [info ] [Thread-1 (]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m19:14:41.012141 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0s, acquire-count=0, language=None, thread-identifier=(15268, 17780), compute-name=) - Creating connection
[0m19:14:41.018170 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710'
[0m19:14:41.019262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Acquired connection on thread (15268, 17780), using default compute resource for model 'None'
[0m19:14:41.019262 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:14:41.035687 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:14:41.036687 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:14:41.053534 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:14:41.056184 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.03801393508911133s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.056184 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.03801393508911133s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Retrieving connection
[0m19:14:41.058801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.04063081741333008s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.058801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.04063081741333008s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Retrieving connection
[0m19:14:41.060052 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m19:14:41.060052 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:14:41.060052 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `hive_metastore`.`saleslt`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m19:14:41.060052 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:14:41.326789 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Connection created
[0m19:14:41.326789 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Created cursor
[0m19:14:41.563731 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Closing cursor
[0m19:14:41.563731 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `hive_metastore`.`saleslt`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:48)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:697)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:574)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:423)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:168)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:167)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:51)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:401)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:386)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:435)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:81)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:674)
	... 35 more
, operation-id=9536e483-3c12-4560-b601-8598eb81dac5
[0m19:14:41.563731 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.603927 [debug] [Thread-1 (]: Runtime Error in test not_null_my_first_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
[0m19:14:41.603927 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.603927 [error] [Thread-1 (]: 1 of 4 ERROR not_null_my_first_dbt_model_id .................................... [[31mERROR[0m in 0.59s]
[0m19:14:41.603927 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:14:41.603927 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:14:41.603927 [info ] [Thread-1 (]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m19:14:41.603927 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.603927 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, now test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778)
[0m19:14:41.603927 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:14:41.603927 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Acquired connection on thread (15268, 17780), using default compute resource for model 'None'
[0m19:14:41.617467 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:14:41.623807 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"
[0m19:14:41.626270 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:14:41.629452 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"
[0m19:14:41.630483 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.026555538177490234s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.632062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.026555538177490234s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Retrieving connection
[0m19:14:41.632062 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"
[0m19:14:41.632062 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `hive_metastore`.`saleslt`.`my_second_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m19:14:41.633868 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Created cursor
[0m19:14:41.754713 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Closing cursor
[0m19:14:41.766741 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `hive_metastore`.`saleslt`.`my_second_dbt_model`
where id is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:48)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:697)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:574)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:423)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:168)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:167)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:51)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:401)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:386)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:435)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:81)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:674)
	... 35 more
, operation-id=ddede95d-2442-4782-9056-7603df7b3d3b
[0m19:14:41.766741 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.770322 [debug] [Thread-1 (]: Runtime Error in test not_null_my_second_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
[0m19:14:41.770322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.770322 [error] [Thread-1 (]: 2 of 4 ERROR not_null_my_second_dbt_model_id ................................... [[31mERROR[0m in 0.17s]
[0m19:14:41.770322 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:14:41.770322 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:14:41.770322 [info ] [Thread-1 (]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m19:14:41.770322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.770322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, now test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321)
[0m19:14:41.770322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:14:41.770322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Acquired connection on thread (15268, 17780), using default compute resource for model 'None'
[0m19:14:41.770322 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:14:41.787999 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"
[0m19:14:41.789999 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:14:41.793986 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"
[0m19:14:41.795528 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.025206327438354492s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.797065 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.026743650436401367s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Retrieving connection
[0m19:14:41.797065 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"
[0m19:14:41.798099 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`my_first_dbt_model`
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:14:41.798099 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Created cursor
[0m19:14:41.936634 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Closing cursor
[0m19:14:41.936634 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`my_first_dbt_model`
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:48)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:697)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:574)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:423)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:168)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:167)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:51)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:401)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:386)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:435)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:81)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:674)
	... 35 more
, operation-id=0b2e0a9e-eaf2-4097-a1e5-987f78404d87
[0m19:14:41.936634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.936634 [debug] [Thread-1 (]: Runtime Error in test unique_my_first_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
[0m19:14:41.936634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:41.936634 [error] [Thread-1 (]: 3 of 4 ERROR unique_my_first_dbt_model_id ...................................... [[31mERROR[0m in 0.17s]
[0m19:14:41.948653 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:14:41.948653 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:14:41.948653 [info ] [Thread-1 (]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m19:14:41.951429 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.014794588088989258s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.951429 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, now test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493)
[0m19:14:41.951429 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.014794588088989258s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:14:41.951429 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.014794588088989258s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Acquired connection on thread (15268, 17780), using default compute resource for model 'None'
[0m19:14:41.951429 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:14:41.951429 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:14:41.951429 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:14:41.961510 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:14:41.963964 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.027330398559570312s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Checking idleness
[0m19:14:41.965520 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.028886079788208008s, acquire-count=1, language=sql, thread-identifier=(15268, 17780), compute-name=) - Retrieving connection
[0m19:14:41.966543 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:14:41.967070 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:14:41.967883 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Created cursor
[0m19:14:42.263025 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=70a3823f-1387-49ab-aa82-2727b840ff46, command-id=Unknown) - Closing cursor
[0m19:14:42.263025 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:48)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:697)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:574)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:423)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:168)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:167)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:51)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:65)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:401)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:386)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:435)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:81)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:674)
	... 35 more
, operation-id=293831da-876c-44ac-8db1-fa1510defc45
[0m19:14:42.263025 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:42.269120 [debug] [Thread-1 (]: Runtime Error in test unique_my_second_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
[0m19:14:42.269120 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2934960145680, session-id=70a3823f-1387-49ab-aa82-2727b840ff46, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(15268, 17780), compute-name=) - Released connection
[0m19:14:42.269120 [error] [Thread-1 (]: 4 of 4 ERROR unique_my_second_dbt_model_id ..................................... [[31mERROR[0m in 0.32s]
[0m19:14:42.269120 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:14:42.269120 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=1.262451171875s, acquire-count=0, language=None, thread-identifier=(15268, 9480), compute-name=) - Checking idleness
[0m19:14:42.269120 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=1.262451171875s, acquire-count=0, language=None, thread-identifier=(15268, 9480), compute-name=) - Reusing connection previously named master
[0m19:14:42.276544 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=1.2698748111724854s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Acquired connection on thread (15268, 9480), using default compute resource
[0m19:14:42.276544 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=1.2698748111724854s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Checking idleness
[0m19:14:42.276544 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=None, name=master, idle-time=1.2698748111724854s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Retrieving connection
[0m19:14:42.277883 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:42.278423 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:42.511577 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=2aa1c537-06a3-4bd9-afdb-330c5aabfebb, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Connection created
[0m19:14:42.512886 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:14:42.513403 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=2aa1c537-06a3-4bd9-afdb-330c5aabfebb, name=master, idle-time=0.001825571060180664s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Checking idleness
[0m19:14:42.513403 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=2aa1c537-06a3-4bd9-afdb-330c5aabfebb, name=master, idle-time=0.001825571060180664s, acquire-count=1, language=None, thread-identifier=(15268, 9480), compute-name=) - Retrieving connection
[0m19:14:42.515488 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:14:42.515488 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:14:42.515488 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2934957890320, session-id=2aa1c537-06a3-4bd9-afdb-330c5aabfebb, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(15268, 9480), compute-name=) - Released connection
[0m19:14:42.515488 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:42.515488 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:42.515488 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:14:42.515488 [debug] [MainThread]: On master: Close
[0m19:14:42.515488 [debug] [MainThread]: Databricks adapter: Connection(session-id=2aa1c537-06a3-4bd9-afdb-330c5aabfebb) - Closing connection
[0m19:14:42.641383 [debug] [MainThread]: Connection 'list_hive_metastore_saleslt' was properly closed.
[0m19:14:42.641383 [debug] [MainThread]: On list_hive_metastore_saleslt: ROLLBACK
[0m19:14:42.641383 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:14:42.641383 [debug] [MainThread]: On list_hive_metastore_saleslt: Close
[0m19:14:42.641383 [debug] [MainThread]: Databricks adapter: Connection(session-id=752d70c1-8760-4a4c-8d43-cc17218b8a38) - Closing connection
[0m19:14:42.715969 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m19:14:42.715969 [debug] [MainThread]: On test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m19:14:42.715969 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:14:42.721709 [debug] [MainThread]: On test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m19:14:42.722224 [debug] [MainThread]: Databricks adapter: Connection(session-id=70a3823f-1387-49ab-aa82-2727b840ff46) - Closing connection
[0m19:14:43.065115 [info ] [MainThread]: 
[0m19:14:43.065641 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 4.19 seconds (4.19s).
[0m19:14:43.068395 [debug] [MainThread]: Command end result
[0m19:14:43.122361 [info ] [MainThread]: 
[0m19:14:43.126876 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m19:14:43.126876 [info ] [MainThread]: 
[0m19:14:43.129291 [error] [MainThread]:   Runtime Error in test not_null_my_first_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
[0m19:14:43.130977 [info ] [MainThread]: 
[0m19:14:43.130977 [error] [MainThread]:   Runtime Error in test not_null_my_second_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 14 pos 5
[0m19:14:43.133918 [info ] [MainThread]: 
[0m19:14:43.135100 [error] [MainThread]:   Runtime Error in test unique_my_first_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_first_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
[0m19:14:43.137121 [info ] [MainThread]: 
[0m19:14:43.138122 [error] [MainThread]:   Runtime Error in test unique_my_second_dbt_model_id (models\example\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`my_second_dbt_model` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 15 pos 5
[0m19:14:43.139256 [info ] [MainThread]: 
[0m19:14:43.141254 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m19:14:43.143285 [debug] [MainThread]: Command `dbt test` failed at 19:14:43.143285 after 7.56 seconds
[0m19:14:43.143285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB378A13D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB378E2C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AB378E2E10>]}
[0m19:14:43.144283 [debug] [MainThread]: Flushing usage events
[0m19:15:24.985072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AF67FE250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AF67FE450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AF67FD150>]}


============================== 19:15:24.989551 | 6e3f53a7-aa0a-464d-94e8-5448a57202a7 ==============================
[0m19:15:24.989551 [info ] [MainThread]: Running with dbt=1.8.6
[0m19:15:24.990567 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:15:25.100623 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:15:25.100623 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:15:25.100623 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:15:26.667130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A9134E410>]}
[0m19:15:26.713287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A90E13790>]}
[0m19:15:26.713287 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m19:15:26.731378 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m19:15:26.922138 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:15:26.922138 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:15:26.965189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A91365050>]}
[0m19:15:27.114252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A9124F550>]}
[0m19:15:27.116093 [info ] [MainThread]: Found 5 models, 7 snapshots, 4 data tests, 9 sources, 596 macros
[0m19:15:27.116093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A915A1D90>]}
[0m19:15:27.120344 [info ] [MainThread]: 
[0m19:15:27.120860 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(12676, 17224), compute-name=) - Creating connection
[0m19:15:27.120860 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:15:27.123389 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Acquired connection on thread (12676, 17224), using default compute resource
[0m19:15:27.131236 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=None, name=list_hive_metastore, idle-time=0s, acquire-count=0, language=None, thread-identifier=(12676, 1916), compute-name=) - Creating connection
[0m19:15:27.132505 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore'
[0m19:15:27.132817 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=None, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 1916), compute-name=) - Acquired connection on thread (12676, 1916), using default compute resource
[0m19:15:27.133890 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=None, name=list_hive_metastore, idle-time=0.0010728836059570312s, acquire-count=1, language=None, thread-identifier=(12676, 1916), compute-name=) - Checking idleness
[0m19:15:27.133890 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=None, name=list_hive_metastore, idle-time=0.0010728836059570312s, acquire-count=1, language=None, thread-identifier=(12676, 1916), compute-name=) - Retrieving connection
[0m19:15:27.134919 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore"
[0m19:15:27.134919 [debug] [ThreadPool]: On list_hive_metastore: GetSchemas(database=hive_metastore, schema=None)
[0m19:15:27.135928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:27.357827 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=d5f06dc9-f10c-4774-a75b-f802f1f428ec, name=list_hive_metastore, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 1916), compute-name=) - Connection created
[0m19:15:27.357827 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d5f06dc9-f10c-4774-a75b-f802f1f428ec, command-id=Unknown) - Created cursor
[0m19:15:27.476305 [debug] [ThreadPool]: SQL status: OK in 0.340 seconds
[0m19:15:27.479173 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d5f06dc9-f10c-4774-a75b-f802f1f428ec, command-id=2acff31d-d287-49c2-b13f-0851a34cab27) - Closing cursor
[0m19:15:27.479173 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282335255248, session-id=d5f06dc9-f10c-4774-a75b-f802f1f428ec, name=list_hive_metastore, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12676, 1916), compute-name=) - Released connection
[0m19:15:27.486093 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=None, name=list_hive_metastore_snapshots, idle-time=0s, acquire-count=0, language=None, thread-identifier=(12676, 13948), compute-name=) - Creating connection
[0m19:15:27.487454 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_snapshots'
[0m19:15:27.487454 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Acquired connection on thread (12676, 13948), using default compute resource
[0m19:15:27.487454 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:27.489960 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:27.489960 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:15:27.489960 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m19:15:27.489960 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:27.760611 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Connection created
[0m19:15:27.760611 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:27.886334 [debug] [ThreadPool]: SQL status: OK in 0.400 seconds
[0m19:15:27.904770 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=9881619b-e6bb-4147-a691-bdd53ffd5850) - Closing cursor
[0m19:15:27.905286 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.14467477798461914s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:27.905286 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.14467477798461914s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:27.905286 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.14467477798461914s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:27.917814 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.15720295906066895s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:27.917814 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:15:27.919140 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:15:27.919140 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m19:15:27.919140 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:28.074340 [debug] [ThreadPool]: SQL status: OK in 0.160 seconds
[0m19:15:28.074340 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=0ea5ad05-6e93-4b40-9ce4-3cff7834a917) - Closing cursor
[0m19:15:28.074340 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.31372857093811035s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:28.089985 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.31372857093811035s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:28.089985 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:15:28.089985 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m19:15:28.089985 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:28.388145 [debug] [ThreadPool]: SQL status: OK in 0.300 seconds
[0m19:15:28.402637 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=c5255887-bcfe-46f3-87e3-957c6395f925) - Closing cursor
[0m19:15:28.402637 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12676, 13948), compute-name=) - Released connection
[0m19:15:28.404148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_snapshots, idle-time=0.0015113353729248047s, acquire-count=0, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:28.404148 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now list_hive_metastore_saleslt)
[0m19:15:28.404148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.0015113353729248047s, acquire-count=0, language=None, thread-identifier=(12676, 13948), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m19:15:28.404148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.0015113353729248047s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Acquired connection on thread (12676, 13948), using default compute resource
[0m19:15:28.404148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.0015113353729248047s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:28.404148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.0015113353729248047s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:28.404148 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:15:28.409365 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m19:15:28.409365 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:28.576710 [debug] [ThreadPool]: SQL status: OK in 0.170 seconds
[0m19:15:28.583891 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=ff530e02-6a49-463b-8afc-14c7d09815b0) - Closing cursor
[0m19:15:28.583891 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.18125414848327637s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:28.583891 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.18125414848327637s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:28.583891 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:15:28.583891 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m19:15:28.583891 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:28.702844 [debug] [ThreadPool]: SQL status: OK in 0.120 seconds
[0m19:15:28.721140 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=3c8abb2d-b6ef-4c44-b5b9-b9bba46488d1) - Closing cursor
[0m19:15:28.721669 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.3190324306488037s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Checking idleness
[0m19:15:28.721669 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.3190324306488037s, acquire-count=1, language=None, thread-identifier=(12676, 13948), compute-name=) - Retrieving connection
[0m19:15:28.721669 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:15:28.721669 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m19:15:28.721669 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=Unknown) - Created cursor
[0m19:15:28.938673 [debug] [ThreadPool]: SQL status: OK in 0.220 seconds
[0m19:15:28.949862 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=84e80136-0d01-4e2d-aec3-631804adf930, command-id=817691db-ba71-4861-8e4f-a96e3472d2ec) - Closing cursor
[0m19:15:28.949862 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1282334764560, session-id=84e80136-0d01-4e2d-aec3-631804adf930, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12676, 13948), compute-name=) - Released connection
[0m19:15:28.949862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A915ED710>]}
[0m19:15:28.954375 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=1.8309857845306396s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Checking idleness
[0m19:15:28.955829 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=1.8324394226074219s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Retrieving connection
[0m19:15:28.956344 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=1.8329553604125977s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Checking idleness
[0m19:15:28.956344 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=1.8329553604125977s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Retrieving connection
[0m19:15:28.956344 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:15:28.956344 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:15:28.956344 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12676, 17224), compute-name=) - Released connection
[0m19:15:28.956344 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:15:28.956344 [info ] [MainThread]: 
[0m19:15:28.964030 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_customer
[0m19:15:28.965088 [info ] [Thread-1 (]: 1 of 5 START sql table model saleslt.dim_customer .............................. [RUN]
[0m19:15:28.967312 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(12676, 19364), compute-name=) - Creating connection
[0m19:15:28.967436 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.medallion_dbt_spark.dim_customer'
[0m19:15:28.968434 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Acquired connection on thread (12676, 19364), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_customer`'
[0m19:15:28.968434 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_customer
[0m19:15:28.972734 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_customer"
[0m19:15:28.980044 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_customer
[0m19:15:28.990585 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:15:29.033336 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.dim_customer"
[0m19:15:29.035844 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.06741023063659668s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:29.036853 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.06841897964477539s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:29.036853 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.06841897964477539s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:29.037853 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.06941866874694824s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:29.038865 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m19:15:29.038865 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.dim_customer"
[0m19:15:29.038865 [debug] [Thread-1 (]: On model.medallion_dbt_spark.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.dim_customer"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`dim_customer`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/customers/dim_customer'
      
      
      as
      

with address_snapshot as (
    select
        AddressID,
        AddressLine1,
        AddressLine2,
        City,
        StateProvince,
        CountryRegion,
        PostalCode
    from `hive_metastore`.`snapshots`.`address_snapshot` where dbt_valid_to is null
)

, customeraddress_snapshot as (
    select
        CustomerId,
        AddressId,
        AddressType
    from `hive_metastore`.`snapshots`.`customeraddress_snapshot` where dbt_valid_to is null
)

, customer_snapshot as (
    select
        CustomerId,
        concat(ifnull(FirstName,' '),' ',ifnull(MiddleName,' '),' ',ifnull(LastName,' ')) as FullName
    from `hive_metastore`.`snapshots`.`customer_snapshot` where dbt_valid_to is null
)

, transformed as (
    select
    row_number() over (order by customer_snapshot.customerid) as customer_sk, -- auto-incremental surrogate key
    customer_snapshot.CustomerId,
    customer_snapshot.fullname,
    customeraddress_snapshot.AddressID,
    customeraddress_snapshot.AddressType,
    address_snapshot.AddressLine1,
    address_snapshot.City,
    address_snapshot.StateProvince,
    address_snapshot.CountryRegion,
    address_snapshot.PostalCode
    from customer_snapshot
    inner join customeraddress_snapshot on customer_snapshot.CustomerId = customeraddress_snapshot.CustomerId
    inner join address_snapshot on customeraddress_snapshot.AddressID = address_snapshot.AddressID
)
select *
from transformed
  
[0m19:15:29.040059 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:15:29.251929 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Connection created
[0m19:15:29.251929 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=Unknown) - Created cursor
[0m19:15:36.188758 [debug] [Thread-1 (]: SQL status: OK in 7.150 seconds
[0m19:15:36.188758 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=91b11435-a63e-4b07-a379-eac6714f0967) - Closing cursor
[0m19:15:36.314916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:36.314916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:36.314916 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A915E8F10>]}
[0m19:15:36.330338 [info ] [Thread-1 (]: 1 of 5 OK created sql table model saleslt.dim_customer ......................... [[32mOK[0m in 7.35s]
[0m19:15:36.331606 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_customer
[0m19:15:36.331606 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_product
[0m19:15:36.331606 [info ] [Thread-1 (]: 2 of 5 START sql table model saleslt.dim_product ............................... [RUN]
[0m19:15:36.333634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_customer, idle-time=0.01871800422668457s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:36.333634 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_customer, now model.medallion_dbt_spark.dim_product)
[0m19:15:36.333634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.01871800422668457s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_customer
[0m19:15:36.333634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.01871800422668457s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Acquired connection on thread (12676, 19364), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_product`'
[0m19:15:36.337427 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_product
[0m19:15:36.337427 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_product"
[0m19:15:36.353793 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_product
[0m19:15:36.357279 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:15:36.358431 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.dim_product"
[0m19:15:36.358431 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.04351496696472168s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:36.363335 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.04841876029968262s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:36.363335 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.dim_product"
[0m19:15:36.363335 [debug] [Thread-1 (]: On model.medallion_dbt_spark.dim_product: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.dim_product"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`dim_product`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/products/dim_product'
      
      
      as
      

with product_snapshot as (
    select
        productId,
        name,
        standardCost,
        listPrice,
        size,
        weight,
        productcategoryid,
        productmodelid,
        sellstartdate,
        sellenddate,
        discontinueddate
    from `hive_metastore`.`snapshots`.`product_snapshot`
    where dbt_valid_to is null
),

product_model_snapshot as (
    select
        productmodelid,
        name,
        CatalogDescription,
        row_number() over (order by name) as model_id
    from `hive_metastore`.`snapshots`.`productmodel_snapshot`
    where dbt_valid_to is null
),


transformed as (
    select
        row_number() over (order by p.productId) as product_sk,
        p.name as product_name,
        p.standardCost,
        p.listPrice,
        p.size,
        p.weight,
        pm.name as model,
        pm.CatalogDescription as description,
        p.sellstartdate,
        p.sellenddate,
        p.discontinueddate
    from product_snapshot p
    left join product_model_snapshot pm on p.productmodelid = pm.productmodelid
)

select * from transformed
  
[0m19:15:36.364976 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=Unknown) - Created cursor
[0m19:15:40.939076 [debug] [Thread-1 (]: SQL status: OK in 4.570 seconds
[0m19:15:40.939076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=4145ac29-c4a8-4de2-bba4-2be6fcb6080f) - Closing cursor
[0m19:15:40.939076 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:40.939076 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:40.939076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A916A8190>]}
[0m19:15:40.945809 [info ] [Thread-1 (]: 2 of 5 OK created sql table model saleslt.dim_product .......................... [[32mOK[0m in 4.61s]
[0m19:15:40.945809 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_product
[0m19:15:40.945809 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.my_first_dbt_model
[0m19:15:40.945809 [info ] [Thread-1 (]: 3 of 5 START sql table model saleslt.my_first_dbt_model ........................ [RUN]
[0m19:15:40.949088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.dim_product, idle-time=0.010011911392211914s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:40.949088 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_product, now model.medallion_dbt_spark.my_first_dbt_model)
[0m19:15:40.949088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.010011911392211914s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_product
[0m19:15:40.949088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.010011911392211914s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Acquired connection on thread (12676, 19364), using default compute resource for model '`hive_metastore`.`saleslt`.`my_first_dbt_model`'
[0m19:15:40.949088 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.my_first_dbt_model
[0m19:15:40.955718 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.my_first_dbt_model"
[0m19:15:40.967440 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.my_first_dbt_model
[0m19:15:40.972381 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:15:40.974765 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.my_first_dbt_model"
[0m19:15:40.976083 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.03700733184814453s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:40.976083 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.03700733184814453s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:40.977167 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.my_first_dbt_model"
[0m19:15:40.977744 [debug] [Thread-1 (]: On model.medallion_dbt_spark.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.my_first_dbt_model"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`my_first_dbt_model`
      
      using delta
      
      
      
      
      
      
      
      as
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  
[0m19:15:40.977744 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=Unknown) - Created cursor
[0m19:15:44.132979 [debug] [Thread-1 (]: SQL status: OK in 3.160 seconds
[0m19:15:44.134527 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=9fc5fc6f-c598-4763-a9e5-f225a2678838) - Closing cursor
[0m19:15:44.134527 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:44.138356 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:44.138872 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A913DFE10>]}
[0m19:15:44.138872 [info ] [Thread-1 (]: 3 of 5 OK created sql table model saleslt.my_first_dbt_model ................... [[32mOK[0m in 3.19s]
[0m19:15:44.138872 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.my_first_dbt_model
[0m19:15:44.138872 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.sales
[0m19:15:44.138872 [info ] [Thread-1 (]: 4 of 5 START sql table model saleslt.sales ..................................... [RUN]
[0m19:15:44.138872 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.004345417022705078s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:44.138872 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.my_first_dbt_model, now model.medallion_dbt_spark.sales)
[0m19:15:44.138872 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.004345417022705078s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.my_first_dbt_model
[0m19:15:44.138872 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.004345417022705078s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Acquired connection on thread (12676, 19364), using default compute resource for model '`hive_metastore`.`saleslt`.`sales`'
[0m19:15:44.138872 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.sales
[0m19:15:44.151232 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.sales"
[0m19:15:44.153260 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.sales
[0m19:15:44.157919 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:15:44.159486 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.sales"
[0m19:15:44.161499 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.02697277069091797s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:44.162498 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.027971506118774414s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:44.162498 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.sales"
[0m19:15:44.163559 [debug] [Thread-1 (]: On model.medallion_dbt_spark.sales: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.sales"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`sales`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/sales/sales'
      
      
      as
      

with salesorderdetail_snapshot as (
    SELECT
        SalesOrderID,
        SalesOrderDetailID,
        OrderQty,
        ProductID,
        UnitPrice,
        UnitPriceDiscount,
        LineTotal
    FROM `hive_metastore`.`snapshots`.`salesorderdetail_snapshot`
),

product_snapshot as (
    SELECT
        ProductID,
        Name,
        ProductNumber,
        Color,
        StandardCost,
        ListPrice,
        Size,
        Weight,
        SellStartDate,
        SellEndDate,
        DiscontinuedDate,
        ThumbNailPhoto,
        ThumbnailPhotoFileName
    FROM `hive_metastore`.`saleslt`.`product`
),

saleorderheader_snapshot as (
    SELECT
        SalesOrderID,
        RevisionNumber,
        OrderDate,
        DueDate,
        ShipDate,
        Status,
        OnlineOrderFlag,
        SalesOrderNumber,
        PurchaseOrderNumber,
        AccountNumber,
        CustomerID,
        ShipToAddressID,
        BillToAddressID,
        ShipMethod,
        CreditCardApprovalCode,
        SubTotal,
        TaxAmt,
        Freight,
        TotalDue,
        Comment,
        row_number() over (partition by SalesOrderID order by SalesOrderID) as row_num
    FROM `hive_metastore`.`saleslt`.`salesorderheader`
),

transformed as (
    select
        sod.SalesOrderID,
        sod.SalesOrderDetailID,
        sod.OrderQty,
        sod.ProductID,
        sod.UnitPrice,
        sod.UnitPriceDiscount,
        sod.LineTotal,
        p.Name,
        p.ProductNumber,
        p.Color,
        p.StandardCost,
        p.ListPrice,
        p.Size,
        p.Weight,
        p.SellStartDate,
        p.SellEndDate,
        p.DiscontinuedDate,
        p.ThumbNailPhoto,
        p.ThumbnailPhotoFileName,
        soh.RevisionNumber,
        soh.OrderDate,
        soh.DueDate,
        soh.ShipDate,
        soh.Status,
        soh.OnlineOrderFlag,
        soh.SalesOrderNumber,
        soh.PurchaseOrderNumber,
        soh.AccountNumber,
        soh.CustomerID,
        soh.ShipToAddressID,
        soh.BillToAddressID,
        soh.ShipMethod,
        soh.CreditCardApprovalCode,
        soh.SubTotal,
        soh.TaxAmt,
        soh.Freight,
        soh.TotalDue,
        soh.Comment
    from salesorderdetail_snapshot sod
    left join product_snapshot p on sod.ProductID = p.ProductID
    left join saleorderheader_snapshot soh on sod.SalesOrderID = soh.SalesOrderID
)

select * from transformed
  
[0m19:15:44.163559 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=Unknown) - Created cursor
[0m19:15:49.742839 [debug] [Thread-1 (]: SQL status: OK in 5.580 seconds
[0m19:15:49.742839 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=a8db9494-6602-40ab-b475-efd684b8615f) - Closing cursor
[0m19:15:49.837426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:49.837426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:49.839246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A915B8810>]}
[0m19:15:49.839246 [info ] [Thread-1 (]: 4 of 5 OK created sql table model saleslt.sales ................................ [[32mOK[0m in 5.70s]
[0m19:15:49.841102 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.sales
[0m19:15:49.841102 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.my_second_dbt_model
[0m19:15:49.841102 [info ] [Thread-1 (]: 5 of 5 START sql view model saleslt.my_second_dbt_model ........................ [RUN]
[0m19:15:49.841102 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.sales, idle-time=0.003675699234008789s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:49.841102 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.sales, now model.medallion_dbt_spark.my_second_dbt_model)
[0m19:15:49.845496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.008070230484008789s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.sales
[0m19:15:49.845496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.008070230484008789s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Acquired connection on thread (12676, 19364), using default compute resource for model '`hive_metastore`.`saleslt`.`my_second_dbt_model`'
[0m19:15:49.846758 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.my_second_dbt_model
[0m19:15:49.846758 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.my_second_dbt_model"
[0m19:15:49.846758 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.my_second_dbt_model
[0m19:15:49.867980 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.my_second_dbt_model"
[0m19:15:49.869130 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.03170442581176758s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Checking idleness
[0m19:15:49.869130 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.03170442581176758s, acquire-count=1, language=sql, thread-identifier=(12676, 19364), compute-name=) - Retrieving connection
[0m19:15:49.869130 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.my_second_dbt_model"
[0m19:15:49.871695 [debug] [Thread-1 (]: On model.medallion_dbt_spark.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.my_second_dbt_model"} */
create or replace view `hive_metastore`.`saleslt`.`my_second_dbt_model`
  
  
  
  as
    -- Use the `ref` function to select from other models

select *
from `hive_metastore`.`saleslt`.`my_first_dbt_model`
where id = 1

[0m19:15:49.871695 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=Unknown) - Created cursor
[0m19:15:51.146191 [debug] [Thread-1 (]: SQL status: OK in 1.270 seconds
[0m19:15:51.154434 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, command-id=914becdd-c9b5-4053-aa11-6a8ea9d11286) - Closing cursor
[0m19:15:51.154434 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:51.154434 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1282339898192, session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(12676, 19364), compute-name=) - Released connection
[0m19:15:51.154434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3f53a7-aa0a-464d-94e8-5448a57202a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012A91B10810>]}
[0m19:15:51.157322 [info ] [Thread-1 (]: 5 of 5 OK created sql view model saleslt.my_second_dbt_model ................... [[32mOK[0m in 1.31s]
[0m19:15:51.157322 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.my_second_dbt_model
[0m19:15:51.157322 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=22.200977563858032s, acquire-count=0, language=None, thread-identifier=(12676, 17224), compute-name=) - Checking idleness
[0m19:15:51.162555 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=22.20566749572754s, acquire-count=0, language=None, thread-identifier=(12676, 17224), compute-name=) - Reusing connection previously named master
[0m19:15:51.162555 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=22.206210613250732s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Acquired connection on thread (12676, 17224), using default compute resource
[0m19:15:51.162555 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=22.206210613250732s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Checking idleness
[0m19:15:51.162555 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=None, name=master, idle-time=22.206210613250732s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Retrieving connection
[0m19:15:51.162555 [debug] [MainThread]: On master: ROLLBACK
[0m19:15:51.162555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:15:51.482125 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=7ccfef87-6574-4723-acb0-4197a590c16c, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Connection created
[0m19:15:51.482125 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:15:51.482125 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=7ccfef87-6574-4723-acb0-4197a590c16c, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Checking idleness
[0m19:15:51.482125 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=7ccfef87-6574-4723-acb0-4197a590c16c, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12676, 17224), compute-name=) - Retrieving connection
[0m19:15:51.482125 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:15:51.482125 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:15:51.482125 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1284036271376, session-id=7ccfef87-6574-4723-acb0-4197a590c16c, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12676, 17224), compute-name=) - Released connection
[0m19:15:51.482125 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:15:51.482125 [debug] [MainThread]: On master: ROLLBACK
[0m19:15:51.492773 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:15:51.493281 [debug] [MainThread]: On master: Close
[0m19:15:51.493281 [debug] [MainThread]: Databricks adapter: Connection(session-id=7ccfef87-6574-4723-acb0-4197a590c16c) - Closing connection
[0m19:15:51.576199 [debug] [MainThread]: Connection 'list_hive_metastore' was properly closed.
[0m19:15:51.576199 [debug] [MainThread]: On list_hive_metastore: Close
[0m19:15:51.576199 [debug] [MainThread]: Databricks adapter: Connection(session-id=d5f06dc9-f10c-4774-a75b-f802f1f428ec) - Closing connection
[0m19:15:51.654425 [debug] [MainThread]: Connection 'list_hive_metastore_saleslt' was properly closed.
[0m19:15:51.654425 [debug] [MainThread]: On list_hive_metastore_saleslt: ROLLBACK
[0m19:15:51.654425 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:15:51.654425 [debug] [MainThread]: On list_hive_metastore_saleslt: Close
[0m19:15:51.670050 [debug] [MainThread]: Databricks adapter: Connection(session-id=84e80136-0d01-4e2d-aec3-631804adf930) - Closing connection
[0m19:15:51.763421 [debug] [MainThread]: Connection 'model.medallion_dbt_spark.my_second_dbt_model' was properly closed.
[0m19:15:51.763421 [debug] [MainThread]: On model.medallion_dbt_spark.my_second_dbt_model: ROLLBACK
[0m19:15:51.763421 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:15:51.764929 [debug] [MainThread]: On model.medallion_dbt_spark.my_second_dbt_model: Close
[0m19:15:51.765993 [debug] [MainThread]: Databricks adapter: Connection(session-id=8c7dd68e-ac28-4cf5-a24e-563df325b897) - Closing connection
[0m19:15:51.850616 [info ] [MainThread]: 
[0m19:15:51.850616 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 24.73 seconds (24.73s).
[0m19:15:51.854786 [debug] [MainThread]: Command end result
[0m19:15:51.918561 [info ] [MainThread]: 
[0m19:15:51.920912 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:15:51.922027 [info ] [MainThread]: 
[0m19:15:51.922027 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m19:15:51.924510 [debug] [MainThread]: Command `dbt run` succeeded at 19:15:51.924510 after 27.00 seconds
[0m19:15:51.925026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AEFF013D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AF01D0210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012AEFF42090>]}
[0m19:15:51.926016 [debug] [MainThread]: Flushing usage events
[0m19:17:49.476644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84082F690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F840871790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F840872D90>]}


============================== 19:17:49.476644 | 1e64f3e0-b181-4d31-af46-f843294bfa28 ==============================
[0m19:17:49.476644 [info ] [MainThread]: Running with dbt=1.8.6
[0m19:17:49.482672 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:17:49.586857 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:17:49.587854 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:17:49.588834 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:17:51.161434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85B2DCC10>]}
[0m19:17:51.205526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AD97C90>]}
[0m19:17:51.205526 [info ] [MainThread]: Registered adapter: databricks=1.8.6
[0m19:17:51.237147 [debug] [MainThread]: checksum: 2f2fb10c73cafe3e79aa104295a8244291492b32b5598ce46af770f7d0bd5194, vars: {}, profile: , target: , version: 1.8.6
[0m19:17:51.450219 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:17:51.451231 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:17:51.540854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85B268090>]}
[0m19:17:51.584660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85B077B50>]}
[0m19:17:51.587056 [info ] [MainThread]: Found 5 models, 7 snapshots, 4 data tests, 9 sources, 596 macros
[0m19:17:51.587056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85B1C8D50>]}
[0m19:17:51.590771 [info ] [MainThread]: 
[0m19:17:51.592634 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191603600, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(23428, 10564), compute-name=) - Creating connection
[0m19:17:51.593499 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:17:51.593499 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191603600, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 10564), compute-name=) - Acquired connection on thread (23428, 10564), using default compute resource
[0m19:17:51.599423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(23428, 11968), compute-name=) - Creating connection
[0m19:17:51.599423 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m19:17:51.599423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Acquired connection on thread (23428, 11968), using default compute resource
[0m19:17:51.599423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:51.599423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:51.599423 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:17:51.599423 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m19:17:51.599423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:17:51.872601 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Connection created
[0m19:17:51.872601 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:52.030456 [debug] [ThreadPool]: SQL status: OK in 0.430 seconds
[0m19:17:52.044917 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=83043f76-39a0-4ca0-bdc9-7ee9aa937cb3) - Closing cursor
[0m19:17:52.044917 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.172316312789917s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.044917 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.172316312789917s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.044917 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.172316312789917s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.044917 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.172316312789917s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.044917 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:17:52.060447 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:17:52.060447 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m19:17:52.060447 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:52.239372 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m19:17:52.257510 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=8d196461-701d-4b35-8c98-d5161f97d783) - Closing cursor
[0m19:17:52.257510 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.38490891456604004s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.257510 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.38490891456604004s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.257510 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m19:17:52.257510 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m19:17:52.257510 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:52.521592 [debug] [ThreadPool]: SQL status: OK in 0.260 seconds
[0m19:17:52.537218 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=cd213b52-8707-488b-8418-3dfe0031e6da) - Closing cursor
[0m19:17:52.537218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 11968), compute-name=) - Released connection
[0m19:17:52.537218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_saleslt, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.537218 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m19:17:52.544230 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.007011890411376953s, acquire-count=0, language=None, thread-identifier=(23428, 11968), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m19:17:52.544230 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.007011890411376953s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Acquired connection on thread (23428, 11968), using default compute resource
[0m19:17:52.544230 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.007011890411376953s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.544230 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.007011890411376953s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.544230 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:17:52.544230 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m19:17:52.544230 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:52.678243 [debug] [ThreadPool]: SQL status: OK in 0.130 seconds
[0m19:17:52.678243 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=69446c5f-8ce5-4f23-a69e-e3cb814ee9eb) - Closing cursor
[0m19:17:52.678243 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.14102482795715332s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.678243 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.14102482795715332s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.678243 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:17:52.693878 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m19:17:52.693878 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:52.935227 [debug] [ThreadPool]: SQL status: OK in 0.240 seconds
[0m19:17:52.935227 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=cbe37ac2-d861-4a33-8cba-cabd42d17f8c) - Closing cursor
[0m19:17:52.935227 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.3980088233947754s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Checking idleness
[0m19:17:52.935227 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.3980088233947754s, acquire-count=1, language=None, thread-identifier=(23428, 11968), compute-name=) - Retrieving connection
[0m19:17:52.935227 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m19:17:52.935227 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m19:17:52.935227 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=Unknown) - Created cursor
[0m19:17:53.122199 [debug] [ThreadPool]: SQL status: OK in 0.190 seconds
[0m19:17:53.138073 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, command-id=0b6891ec-4634-4098-b52a-c9605d55269b) - Closing cursor
[0m19:17:53.138073 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2166191359568, session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3, name=list_hive_metastore_snapshots, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 11968), compute-name=) - Released connection
[0m19:17:53.142072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e64f3e0-b181-4d31-af46-f843294bfa28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85B317010>]}
[0m19:17:53.142072 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191603600, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 10564), compute-name=) - Released connection
[0m19:17:53.142072 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:17:53.142072 [info ] [MainThread]: 
[0m19:17:53.159851 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.my_first_dbt_model
[0m19:17:53.161738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0s, acquire-count=0, language=None, thread-identifier=(23428, 21896), compute-name=) - Creating connection
[0m19:17:53.162763 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.medallion_dbt_spark.my_first_dbt_model'
[0m19:17:53.163297 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`saleslt`.`my_first_dbt_model`'
[0m19:17:53.164312 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.my_first_dbt_model
[0m19:17:53.169728 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.my_first_dbt_model"
[0m19:17:53.169728 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.my_first_dbt_model
[0m19:17:53.173842 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.174836 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.174836 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.my_first_dbt_model
[0m19:17:53.177377 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.address_snapshot
[0m19:17:53.179064 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_first_dbt_model, idle-time=0.002541065216064453s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.179064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.my_first_dbt_model, now snapshot.medallion_dbt_spark.address_snapshot)
[0m19:17:53.179064 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.004228353500366211s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.my_first_dbt_model
[0m19:17:53.181029 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.006193637847900391s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`address_snapshot`'
[0m19:17:53.181542 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.address_snapshot
[0m19:17:53.181542 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.address_snapshot
[0m19:17:53.181542 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.181542 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.181542 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.address_snapshot
[0m19:17:53.181542 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customer_snapshot
[0m19:17:53.189574 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.190185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.address_snapshot, now snapshot.medallion_dbt_spark.customer_snapshot)
[0m19:17:53.190185 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.008643150329589844s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.address_snapshot
[0m19:17:53.191983 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.010441780090332031s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`customer_snapshot`'
[0m19:17:53.191983 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customer_snapshot
[0m19:17:53.194738 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customer_snapshot
[0m19:17:53.194738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.194738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.194738 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customer_snapshot
[0m19:17:53.194738 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m19:17:53.194738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.194738 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customer_snapshot, now snapshot.medallion_dbt_spark.customeraddress_snapshot)
[0m19:17:53.194738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customer_snapshot
[0m19:17:53.202257 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`customeraddress_snapshot`'
[0m19:17:53.202787 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m19:17:53.202787 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m19:17:53.207389 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.208369 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.208369 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m19:17:53.210440 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.product_snapshot
[0m19:17:53.211500 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0020704269409179688s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.212006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customeraddress_snapshot, now snapshot.medallion_dbt_spark.product_snapshot)
[0m19:17:53.212006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0036368370056152344s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m19:17:53.212006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0036368370056152344s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`product_snapshot`'
[0m19:17:53.213439 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.product_snapshot
[0m19:17:53.213439 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.product_snapshot
[0m19:17:53.213439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.213439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.213439 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.product_snapshot
[0m19:17:53.213439 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m19:17:53.213439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.213439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.product_snapshot, now snapshot.medallion_dbt_spark.productmodel_snapshot)
[0m19:17:53.213439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.product_snapshot
[0m19:17:53.222177 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.008737564086914062s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`productmodel_snapshot`'
[0m19:17:53.222177 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m19:17:53.227262 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m19:17:53.228262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.228262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.229262 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m19:17:53.229262 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m19:17:53.231262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.002000093460083008s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.231262 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.productmodel_snapshot, now snapshot.medallion_dbt_spark.salesorderdetail_snapshot)
[0m19:17:53.232242 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.003979921340942383s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.productmodel_snapshot
[0m19:17:53.232242 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.003979921340942383s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderdetail_snapshot`'
[0m19:17:53.233343 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m19:17:53.237906 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m19:17:53.238902 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.239884 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.239884 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m19:17:53.240869 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m19:17:53.241912 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.003009796142578125s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.241912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderdetail_snapshot, now snapshot.medallion_dbt_spark.salesorderheader_snapshot)
[0m19:17:53.242947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.004045009613037109s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m19:17:53.242947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.004045009613037109s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderheader_snapshot`'
[0m19:17:53.243948 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m19:17:53.246943 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m19:17:53.247945 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.248923 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.248923 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m19:17:53.249936 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.my_second_dbt_model
[0m19:17:53.250924 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0020003318786621094s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.250924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderheader_snapshot, now model.medallion_dbt_spark.my_second_dbt_model)
[0m19:17:53.252332 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.003408193588256836s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m19:17:53.252332 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.003408193588256836s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`saleslt`.`my_second_dbt_model`'
[0m19:17:53.253364 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.my_second_dbt_model
[0m19:17:53.257793 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.my_second_dbt_model"
[0m19:17:53.258940 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.my_second_dbt_model
[0m19:17:53.259457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.259457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.259457 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.my_second_dbt_model
[0m19:17:53.259457 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:17:53.259457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.my_second_dbt_model, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.259457 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.my_second_dbt_model, now test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710)
[0m19:17:53.259457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.my_second_dbt_model
[0m19:17:53.259457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model 'None'
[0m19:17:53.259457 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:17:53.276045 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:17:53.277076 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:17:53.277076 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.278435 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.279469 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:17:53.279469 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:17:53.280855 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, idle-time=0.002419710159301758s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.280855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710, now test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321)
[0m19:17:53.282355 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.003920555114746094s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:17:53.282886 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.004450321197509766s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model 'None'
[0m19:17:53.282886 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:17:53.289896 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321"
[0m19:17:53.291555 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:17:53.291555 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.292992 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.292992 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:17:53.292992 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_customer
[0m19:17:53.292992 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.295963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321, now model.medallion_dbt_spark.dim_customer)
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0029714107513427734s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_my_first_dbt_model_id.16e066b321
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0029714107513427734s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_customer`'
[0m19:17:53.295963 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_customer
[0m19:17:53.295963 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_customer"
[0m19:17:53.295963 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_customer
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.295963 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_customer
[0m19:17:53.295963 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_product
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.295963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_customer, now model.medallion_dbt_spark.dim_product)
[0m19:17:53.295963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_customer
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_product`'
[0m19:17:53.307475 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_product
[0m19:17:53.307475 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_product"
[0m19:17:53.307475 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_product
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.307475 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_product
[0m19:17:53.307475 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.sales
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.dim_product, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.307475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_product, now model.medallion_dbt_spark.sales)
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_product
[0m19:17:53.307475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model '`hive_metastore`.`saleslt`.`sales`'
[0m19:17:53.307475 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.sales
[0m19:17:53.323336 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.sales"
[0m19:17:53.323336 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.sales
[0m19:17:53.323336 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.325968 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.325968 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.sales
[0m19:17:53.327341 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:17:53.327341 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=model.medallion_dbt_spark.sales, idle-time=0.0013730525970458984s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.327341 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.sales, now test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778)
[0m19:17:53.327341 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0013730525970458984s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.sales
[0m19:17:53.327341 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0013730525970458984s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model 'None'
[0m19:17:53.327341 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:17:53.327341 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778"
[0m19:17:53.327341 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:17:53.327341 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.327341 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.327341 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:17:53.327341 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:17:53.339374 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, idle-time=0.012032508850097656s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Checking idleness
[0m19:17:53.339374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778, now test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493)
[0m19:17:53.339374 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.012032508850097656s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_my_second_dbt_model_id.151b76d778
[0m19:17:53.341798 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.012032508850097656s, acquire-count=1, language=sql, thread-identifier=(23428, 21896), compute-name=) - Acquired connection on thread (23428, 21896), using default compute resource for model 'None'
[0m19:17:53.341798 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:17:53.344631 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:17:53.344631 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:17:53.344631 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.344631 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2166200684304, session-id=None, name=test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(23428, 21896), compute-name=) - Released connection
[0m19:17:53.344631 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493
[0m19:17:53.344631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:17:53.352038 [debug] [MainThread]: Connection 'list_hive_metastore_snapshots' was properly closed.
[0m19:17:53.352555 [debug] [MainThread]: On list_hive_metastore_snapshots: ROLLBACK
[0m19:17:53.352555 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:17:53.352555 [debug] [MainThread]: On list_hive_metastore_snapshots: Close
[0m19:17:53.352555 [debug] [MainThread]: Databricks adapter: Connection(session-id=1c4e0c8c-920c-4761-84a3-31fc115427a3) - Closing connection
[0m19:17:53.433463 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m19:17:53.433463 [debug] [MainThread]: Command end result
[0m19:17:53.877964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191022992, session-id=None, name=generate_catalog, idle-time=0s, acquire-count=0, language=None, thread-identifier=(23428, 10564), compute-name=) - Creating connection
[0m19:17:53.877964 [debug] [MainThread]: Acquiring new databricks connection 'generate_catalog'
[0m19:17:53.877964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191022992, session-id=None, name=generate_catalog, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 10564), compute-name=) - Acquired connection on thread (23428, 10564), using default compute resource
[0m19:17:53.877964 [info ] [MainThread]: Building catalog
[0m19:17:53.885459 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0s, acquire-count=0, language=None, thread-identifier=(23428, 172), compute-name=) - Creating connection
[0m19:17:53.885459 [debug] [ThreadPool]: Acquiring new databricks connection '('hive_metastore', 'saleslt')'
[0m19:17:53.888198 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Acquired connection on thread (23428, 172), using default compute resource
[0m19:17:53.889338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0.0011403560638427734s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:53.889338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0.0011403560638427734s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Retrieving connection
[0m19:17:53.889338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0.0011403560638427734s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:53.889338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=None, name=('hive_metastore', 'saleslt'), idle-time=0.0011403560638427734s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Retrieving connection
[0m19:17:53.889338 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:17:53.889338 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'saleslt')"
[0m19:17:53.889338 [debug] [ThreadPool]: On ('hive_metastore', 'saleslt'): /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'saleslt')"} */

      select current_catalog()
  
[0m19:17:53.889338 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:17:54.195673 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'saleslt'), idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Connection created
[0m19:17:54.195673 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=Unknown) - Created cursor
[0m19:17:54.387952 [debug] [ThreadPool]: SQL status: OK in 0.500 seconds
[0m19:17:54.387952 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=567da581-6201-4115-84f3-6bb78b5e9a07) - Closing cursor
[0m19:17:54.387952 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'saleslt'), idle-time=0.19227910041809082s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:54.387952 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'saleslt'), idle-time=0.19227910041809082s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Retrieving connection
[0m19:17:54.387952 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'saleslt')"
[0m19:17:54.387952 [debug] [ThreadPool]: On ('hive_metastore', 'saleslt'): /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'saleslt')"} */
show table extended in `hive_metastore`.`saleslt` like 'productmodel|productdescription|product|customeraddress|address|my_first_dbt_model|productcategory|salesorderheader|salesorderdetail|dim_customer|my_second_dbt_model|dim_product|sales|customer'
  
[0m19:17:54.387952 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=Unknown) - Created cursor
[0m19:17:55.215571 [debug] [ThreadPool]: SQL status: OK in 0.830 seconds
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=53e7e933-5666-4caa-82e3-e022e35c1aff) - Closing cursor
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'saleslt'), idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 172), compute-name=) - Released connection
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'saleslt'), idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:55.231195 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly ('hive_metastore', 'saleslt'), now ('hive_metastore', 'snapshots'))
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 172), compute-name=) - Reusing connection previously named ('hive_metastore', 'saleslt')
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Acquired connection on thread (23428, 172), using default compute resource
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:55.231195 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Retrieving connection
[0m19:17:55.231195 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'snapshots')"
[0m19:17:55.231195 [debug] [ThreadPool]: On ('hive_metastore', 'snapshots'): /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'snapshots')"} */

      select current_catalog()
  
[0m19:17:55.246825 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=Unknown) - Created cursor
[0m19:17:55.499028 [debug] [ThreadPool]: SQL status: OK in 0.250 seconds
[0m19:17:55.499028 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=c2eed89d-4aa7-4ea0-81ca-c9c9763973eb) - Closing cursor
[0m19:17:55.499028 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.2678334712982178s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Checking idleness
[0m19:17:55.499028 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.2678334712982178s, acquire-count=1, language=None, thread-identifier=(23428, 172), compute-name=) - Retrieving connection
[0m19:17:55.499028 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'snapshots')"
[0m19:17:55.499028 [debug] [ThreadPool]: On ('hive_metastore', 'snapshots'): /* {"app": "dbt", "dbt_version": "1.8.6", "dbt_databricks_version": "1.8.6", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'snapshots')"} */
show table extended in `hive_metastore`.`snapshots` like 'customer_snapshot|salesorderdetail_snapshot|salesorderheader_snapshot|product_snapshot|productmodel_snapshot|customeraddress_snapshot|address_snapshot'
  
[0m19:17:55.499028 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=Unknown) - Created cursor
[0m19:17:56.187249 [debug] [ThreadPool]: SQL status: OK in 0.690 seconds
[0m19:17:56.187249 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, command-id=58522d50-8866-4ae4-b155-ee7e5a4f34d3) - Closing cursor
[0m19:17:56.187249 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2165745840720, session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5, name=('hive_metastore', 'snapshots'), idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 172), compute-name=) - Released connection
[0m19:17:56.187249 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2166191022992, session-id=None, name=generate_catalog, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(23428, 10564), compute-name=) - Released connection
[0m19:17:56.261489 [info ] [MainThread]: Catalog written to C:\Users\huynh\Desktop\Medallion-Spark-Azure-DBt\medallion_dbt_spark\target\catalog.json
[0m19:17:56.265930 [debug] [MainThread]: Command `dbt docs generate` succeeded at 19:17:56.264925 after 6.86 seconds
[0m19:17:56.265930 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m19:17:56.265930 [debug] [MainThread]: Connection '('hive_metastore', 'snapshots')' was properly closed.
[0m19:17:56.265930 [debug] [MainThread]: On ('hive_metastore', 'snapshots'): ROLLBACK
[0m19:17:56.267635 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:17:56.267635 [debug] [MainThread]: On ('hive_metastore', 'snapshots'): Close
[0m19:17:56.267635 [debug] [MainThread]: Databricks adapter: Connection(session-id=f0a11f74-90b8-4816-971b-b2a47af9eba5) - Closing connection
[0m19:17:56.371336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F83A1A4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F83F52FF10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F83FC72890>]}
[0m19:17:56.372405 [debug] [MainThread]: Flushing usage events
[0m19:18:04.444135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B609F7E0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B609ACDB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B609FAB750>]}


============================== 19:18:04.448393 | b5f92eaf-3edd-4ae1-bf7f-e2348d9f2ed6 ==============================
[0m19:18:04.448393 [info ] [MainThread]: Running with dbt=1.8.6
[0m19:18:04.448393 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\huynh\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\huynh\\Desktop\\Medallion-Spark-Azure-DBt\\medallion_dbt_spark\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:18:04.556251 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:18:04.557375 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:18:04.558413 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:18:06.167535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b5f92eaf-3edd-4ae1-bf7f-e2348d9f2ed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B6249DA0D0>]}
[0m19:18:06.214370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b5f92eaf-3edd-4ae1-bf7f-e2348d9f2ed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B624503890>]}
